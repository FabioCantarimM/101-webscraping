# Workshop Crawler

# Projeto de Web Scraping com Redis e MongoDB

## Visão Geral

Este projeto é focado em técnicas de Web Scraping usando Python. Utilizamos Redis e MongoDB como nossos bancos de dados para armazenamento e gerenciamento de dados coletados durante o processo de raspagem de dados.

### 1. Redis

Redis é um armazenamento de estrutura de dados em memória, usado como banco de dados, cache e message broker. Ele suporta estruturas de dados como strings, hashes, listas, sets, sorted sets com consultas de intervalo, bitmaps, hyperloglogs, geospatial indexes e streams. Redis tem um desempenho excepcional por manter os dados em memória.

### 2. MongoDB

MongoDB é um banco de dados NoSQL orientado a documentos. É escalável e flexível, permitindo que você armazene dados em um formato semelhante ao JSON com esquemas dinâmicos. Isso torna a integração de dados em certos tipos de aplicações mais fácil e rápida.

### 3. Web Scraping

Web Scraping é a técnica de extrair dados de websites. Este processo envolve fazer requisições HTTP para o servidor do site desejado, coletar dados da página e, em seguida, analisar esses dados para extrair informações úteis. Utilizamos Python e suas bibliotecas como BeautifulSoup e Scrapy para realizar estas tarefas.

